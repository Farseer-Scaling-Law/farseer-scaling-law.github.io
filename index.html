<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Predictable Scale: Part I — Optimal Hyperparameter Scaling Law in
        Large Language Model Pretraining">
  <!-- <meta name="keywords" content="Nerfies, D-NeRF, NeRF"> -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Predictable Scale: Part I</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Predictable Scale: Part I — Optimal Hyperparameter Scaling Law in
            Large Language Model Pretraining</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Houyi Li<sup>1,2</sup>,
            </span>
            <span class="author-block">
              Wenzhen Zheng<sup>1</sup>,
            </span>
            <span class="author-block">
              Jingcheng Hu<sup>1,3</sup>,
            </span>
            <span class="author-block">
              Qiufeng Wang<sup>1</sup>,
            </span>
            <span class="author-block">
              Hanshan Zhang<sup>1</sup>,
            </span>
            <span class="author-block">
              Zili Wang<sup>1</sup>,
            </span>
            <span class="author-block">
              Shijie Xuyang<sup>1,2</sup>
            </span>
            <span class="author-block">
              Yuantao Fan<sup>1</sup>
            </span>
            <span class="author-block">
              Shuigeng Zhou<sup>2</sup>
            </span>
            <span class="author-block">
              Xiangyu Zhang<sup>1,4</sup>
            </span>
            <span class="author-block">
              Daxin Jiang<sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>StepFun</span>
            <span class="author-block"><sup>2</sup>Fudan University</span>
            <span class="author-block"><sup>3</sup>Tsinghua University</span>
            <span class="author-block"><sup>4</sup>Megvii Technology</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- 工具 -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="tool-container">
      <div class="tool-loading" id="toolLoader">
        <div class="lds-ring">
          <div></div><div></div><div></div><div></div>
        </div>
      </div>
      <iframe src="tool.html" 
              class="tool-iframe"
              loading="lazy"
              title="Hyperparameter Optimization Tool"
              onload="document.getElementById('toolLoader').style.display='none'"></iframe>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The impressive capabilities of Large Language Models (LLMs) across diverse tasks are now well-established, yet their effective deployment necessitates careful hyperparameter optimization.
            Through extensive empirical studies involving grid search across diverse configurations, we discover universal scaling laws
            governing these hyperparameters: optimal learning rate follows a power-law relationship with both model parameters and data sizes, while optimal batch
            size scales primarily with data sizes. 
          </p>
          <p>
            Our analysis reveals a convex optimization landscape for hyperparameters under fixed models and data size conditions. 
            This convexity implies an optimal hyperparameter plateau. We contribute a universal, plug-and-play optimal hyperparameter tool for the community. 
            Its estimated values on the test set are merely 0.07% away from the globally optimal LLM performance found via exhaustive search.  
          </p>
          <p>
            These laws demonstrate remarkable robustness across variations in model sparsity, training data distribution, and model shape. 
            To our best known, this is the first work that unifies different model shapes and structures, 
            such as Mixture-of-Experts models and dense transformers, 
            as well as to establish optimal hyperparameter scaling laws across diverse data distributions. 
            This exhaustive optimization process demands substantial computational resources, 
            utilizing nearly <b>one million</b> NVIDIA H800 GPU hours to train <b>3,700</b> LLMs of varying sizes and hyperparameters from scratch and consuming approximately <b>100 trillion tokens</b> in total. 
            To facilitate reproducibility and further research, we will progressively release all loss measurements and model checkpoints through our designated repository.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <figure class="image mb-5"> <!-- mb-5 控制下边距 -->
        <img src="./static/images/img3.png" alt="img3">
        <figcaption class="mt-2 has-text-grey">
          Topological Invariance Across Varied Model Shape
        </figcaption>
      </figure>

      <div class="column is-full-width">

        <!-- 第二行图块 -->
        <div class="tile is-ancestor mt-6">
          <div class="tile is-parent">
            <!-- 图块3 -->
            <div class="tile is-child box has-background-light">
              <figure class="image is-3by2">
                <img src="./static/images/img3.png" alt="示例图3" class="has-rounded-border">
              </figure>
              <div class="content mt-4">
                <p class="has-text-grey">Topological Invariance Across Varied Model Shape</p>
              </div>
            </div>
          </div>
        </div>

      </div>
    </div>
  </div>
</section>


    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>







<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{,
  author    = {Houyi Li, Wenzhen Zheng, Jingcheng Hu, Qiufeng Wang, Hanshan Zhang, Zili Wang, Shijie Xuyang, Yuantao Fan,
              Shuigeng Zhou, Xiangyu Zhang, Daxin Jiang},
  title     = {Predictable Scale: Part I — Optimal Hyperparameter Scaling Law in Large Language Model Pretraining},
  journal   = {arXiv},
  year      = {2025},
}</code></pre>
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on the <a href="https://nerfies.github.io">Nerfies</a> project page. 
            If you want to reuse their <a href="https://github.com/nerfies/nerfies.github.io">source code</a>, 
            please credit them appropriately.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
