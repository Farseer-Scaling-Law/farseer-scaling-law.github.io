<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Predictable Scale: Part I — Optimal Hyperparameter Scaling Law in
        Large Language Model Pretraining">
  <!-- <meta name="keywords" content="Nerfies, D-NeRF, NeRF"> -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Predictable Scale: Part I</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>

  <style>
    .katex { font-size: 1.1em; }
    .formula-box { padding: 1rem; background: #f8f9fa; }
  </style>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <span class="highlight-title">Predictable Scale: Part I — Optimal Hyperparameter Scaling Law in 
            Large Language Model Pretraining</span>
          </h1>
            <style>
            /* 动态渐变效果 */
            .highlight-title {
              background: linear-gradient(
                45deg,
                #003f5c 0%,
                #374c80 12.5%,
                #7a5195 25%,
                #bc5090 37.5%,
                #ef5675 50%,
                #f97170 62.5%,
                #ff7c43 75%,
                #ffa600 87.5%
              );
              background-size: 400% 400%;
              -webkit-background-clip: text;
              background-clip: text;
              color: transparent;
              font-style: italic;
              animation: gradientShift 12s ease infinite;
              text-shadow: 0 2px 4px rgba(0,0,0,0.1);
            }

            @keyframes gradientShift {
              0% { background-position: 0% 50%; }
              50% { background-position: 100% 50%; }
              100% { background-position: 0% 50%; }
            }
            
            @media (prefers-reduced-motion: reduce) {
              .highlight-title {
                animation: none;
                background: #FF6B6B; /* 降级为纯色 */
              }
            }
            /* 保持原有字体样式 */
            .publication-title {
              font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            }
            </style>
          <div class="publication-authors">
            <span class="author-block">
              <span class="author-name">Houyi Li</span><sup style="font-size: 0.6rem;">1,2</sup>
            </span>
            <span class="author-block">
              <span class="author-name">Wenzhen Zheng</span><sup style="font-size: 0.6rem;">1</sup>
            </span>
            <span class="author-block">
              <span class="author-name">Jingcheng Hu</span><sup style="font-size: 0.6rem;">1,3</sup>
            </span>
            <span class="author-block">
              <span class="author-name">Qiufeng Wang</span><sup style="font-size: 0.6rem;">1</sup>
            </span>
            <span class="author-block">
              <span class="author-name">Hanshan Zhang</span><sup style="font-size: 0.6rem;">1</sup>
            </span>
            <span class="author-block">
              <span class="author-name">Zili Wang</span><sup style="font-size: 0.6rem;">1</sup>
            </span>
            <div style="width: 100%; height: 0;"></div>
            <span class="author-block">
              <span class="author-name">Shijie Xuyang</span><sup style="font-size: 0.6rem;">1,2</sup>
            </span>
            <span class="author-block">
              <span class="author-name">Yuantao Fan</span><sup style="font-size: 0.6rem;">1</sup>
            </span>
            <span class="author-block">
              <span class="author-name">Shuigeng Zhou</span><sup style="font-size: 0.6rem;">2</sup>
            </span>
            <span class="author-block">
              <span class="author-name">Xiangyu Zhang</span><sup style="font-size: 0.6rem;">1,4</sup>
            </span>
            <span class="author-block">
              <span class="author-name">Daxin Jiang</span><sup style="font-size: 0.6rem;">1</sup>
            </span>
          </div>
          <div class="institutional-affiliations" style="text-align: center; margin-top: 0.25rem; font-size: 0.9rem;">
              <span style="margin-right: 1rem;"><sup style="font-size: 0.6rem;">1</sup>StepFun</span>
              <span style="margin-right: 1rem;"><sup style="font-size: 0.6rem;">2</sup>Fudan University</span>
              <span style="margin-right: 1rem;"><sup style="font-size: 0.6rem;">3</sup>Tsinghua University</span>
              <span><sup style="font-size: 0.6rem;">4</sup>Megvii Technology</span>
          </div>
          

            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2503.04715"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2503.04715"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/step-law/steplaw"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://wandb.ai/billzid/predictable-scale"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-wave-square"></i>
                  </span>
                  <span>Wandb</span>
                </a>
              </span>
            </div>

          </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered mb-6">
      <div class="column is-full-width">
        <figure class="image mb-5"> 
          <img src="./static/images/img1.png" alt="img1">
          <figcaption class="mt-2" style="color: #333">
            <strong style="font-weight: 900; color: #000;">Figure 1. The hyperparameter space for models 
            with 400M parameters trained on 40B tokens (left) and 1B parameters trained on 100B tokens (right).</strong>
            All contour lines shown here represent the genuinely converged Train Smooth Loss obtained from small models 
            trained from scratch. The contour lines in the two figures respectively originate from two groups 
            totaling 240 small models with different hyperparameters (Grid Search) trained end-to-end. 
            The Global Minimum is derived from the 120 small models as the one with the minimal final Train Smooth Loss. 
            The contour lines illustrate the relative distance from the Global Minimum in terms of the final loss. 
            Data points exceeding +2% are excluded from the visualization. 
            All mentioned methods have been converted to predict OptimalToken-Wise BatchSize.
          </figcaption>
        </figure>
      </div>
    </div>
    
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="abstract-box has-background-white-bis p-6">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3 elegant-title">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              We first present the unified optimal hyperparameter scaling laws, termed Step Law, 
              that generalizes across diverse model shapes, architectures, and data distributions. 
            </p>
            <p>
              Our findings demonstrate remarkable accuracy, with estimated values on test sets deviating 
              by only 0.09% from the globally optimal LLM performance identified through exhaustive search.
            </p>
            <p>
              This research entails a significant computational investment, 
              utilizing nearly <b>one million NVIDIA H800 GPU hours</b> to train <b>3,700 LLMs</b> 
              of varying sizes and hyperparameters from scratch, consuming approximately 
              <b>100 trillion tokens</b> in total. To support reproducibility and advance the field for LLM pre-training, 
              we will progressively release all loss measurements and model checkpoints through our designated repository.
              The universal, plug-and-play <a href = "#steplawtool">optimal hyperparameter tool</a> is provided for the community.
            </p>
          </div>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- 文字描述部分 -->
    <div class="formula-caption">
      <p class="caption-text">
        <span class="highlight-term">Step Law</span> demonstrates that the optimal 
        batch size <span class="math-inline">$B(D)$</span> exhibits a primary dependence 
        on dataset size <span class="math-inline">$D$</span>, while the optimal learning rate 
        <span class="math-inline">$\eta(N, D)$</span> manifests a joint dependence on both 
        model parameters <span class="math-inline">$N$</span> and dataset size 
        <span class="math-inline">$D$</span>.
      </p>
    </div>

    <!-- 公式区块 -->
    <div class="formula-container">
      <div class="math-display">
      $$
        \begin{aligned}
        \eta(N, D) & = 1.79N^{-0.713}D^{0.307}  \\
        B(D)       & = 0.58D^{0.571}     
        \end{aligned}
      $$
      </div>
    </div>
  </div>
</section>

<style>
/* 公式容器样式 */
.formula-container {
  background: #f8f9fa; 
  border-radius: 30px;  
  padding: 0.6rem 0.6rem; 
  margin: 1.0rem auto 0rem;
  margin-bottom: 0rem;
  width: fit-content; 
  display: block;
  box-shadow: 0 2px 6px rgba(0, 0, 0, 0.08); 
  border: 1px solid #e0e0e0; /
}

/* 行内公式样式 */
.math-inline {
  font-family: "KaTeX_Math", sans-serif;
  color: #1a237e;
  font-style: italic;
  padding: 0 0.3rem;
  background: rgba(255, 255, 255, 0.9);
  border-radius: 4px;
  box-shadow: 0 1px 2px rgba(0,0,0,0.05);
}

/* 数学公式显示 */
.math-display {
  text-align: center;
  padding: 1rem;
}

.katex {
  font-size: 1.2rem !important;
  color: #000;
}

/* 文字描述样式 */
.formula-caption {
  border-left: 3px solid #4a90e2;
  padding-left: 1rem;
}

.caption-text {
  color: #333;
  line-height: 1.8;
  font-size: 0.95rem;
  font-family: 'Arial', sans-serif;
}

.highlight-term {
  color: #1565c0;
  font-weight: 700;
  letter-spacing: -0.3px;
}

/* 加载 KaTeX 字体 */
@import url('https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css');
</style>


<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 elegant-title">Loss Landscape Convexity</h2>
    <div class="columns is-centered mb-6">
      <div class="column is-full-width">
        <figure class="image mb-5"> 
          <img src="./static/images/img2.png" alt="img2">
          <figcaption class="mt-2" style="color: #333">
            <strong style="font-weight: 900; color: #000;">Learning Rate vs. Batch Size Loss Landscape Analysis for 1B Model (Trained on 100B Tokens):</strong> 
            Scatter Plots and 3D Surface Visualizations of Hyperparameter Sensitivity.
          </figcaption>
        </figure>
      </div>
    </div>

    <h2 class="title is-3 elegant-title">Generalization of the Step Law</h2>
    <div class="columns is-centered mb-6">
      <div class="column is-full-width">
        <figure class="image mb-5"> 
          <img src="./static/images/img3.png" alt="img3">
          <figcaption class="mt-2" style="color: #333">
            <strong style="font-weight: 900; color: #000;">Topological Invariance Across Varied Model Shape.</strong>
          </figcaption>
        </figure>
      </div>
    </div>

    <div class="columns is-centered mb-6">
      <div class="column is-full-width">
        <figure class="image mb-5">
          <img src="./static/images/img4.png" alt="img4">
          <figcaption class="mt-2" style="color: #333">
            <strong style="font-weight: 900; color: #000;">Validation loss landscapes of MoE models under varying sparsity ratios N<sub>a</sub>/N.</strong>
            Left: Low sparsity N<sub>a</sub>/N=0.27. Middle: Medium sparsity N<sub>a</sub>/N=0.58. 
            Right: Medium sparsity at D=8.0B. 
            Our method consistently approximates global minima across sparsity regimes.
          </figcaption>
        </figure>
      </div>
    </div>
    
    <div class="columns is-centered mb-6">
      <div class="column is-full-width">
        <figure class="image mb-5"> 
          <img src="./static/images/img5.png" alt="img5">
          <figcaption class="mt-2" style="color: #333">
            <strong style="font-weight: 900; color: #000;">Configuration Space Analysis under Different Data Recipes.</strong>
            Our method demonstrates stable convergence patterns across varying data compositions.
          </figcaption>
        </figure>
      </div>
    </div>

    <h2 class="title is-3 elegant-title">Experimental Details</h2>
    <div class="columns is-centered mb-6">
      <div class="column is-full-width">
        <figure class="image mb-5"> 
          <img src="./static/images/img6.png" alt="img6">
          <figcaption class="mt-2" style="color: #333">
            <strong style="font-weight: 900; color: #000;">Comparison of learning rate schedules.</strong> These contour
            plots illustrate two distinct learning rate schedules. <strong style="font-weight: 900; color: #000;">Blue
            contours</strong> represent the <i>conventional decay schedule</i>, where the
            minimum learning rate min_lr is set to one-tenth of the maximum
            learning rate max_lr/10. <strong style="font-weight: 900; color: #000;">Red contours</strong> depict our
            proposed <i>final learning rate schedule</i>, with a constant
            minimum learning rate of min_lr = 10<sup>-5</sup>. The visualization reveals
            that the conventional decay method leads to a discernible <strong style="font-weight: 900; color: #000;">leftward
            bias</strong> in the optimal learning rate range, indicated by the shift of the lowest
            loss region towards lower learning rates in the blue contours compared to
            the red.
          </figcaption>
        </figure>
      </div>
    </div>


    <div class="columns is-centered mb-6">
      <div class="column is-full-width">
        <figure class="image mb-5"> 
          <img src="./static/images/img7.png" alt="img7">
          <figcaption class="mt-2" style="color: #333">
            <strong style="font-weight: 900; color: #000;">
            <p>(a) Scatter points indicate empirical optimal learning rate vs. batch size for model scale N;</p>
            <p>(b) Analogous results for dataset scale D.</p>
            </strong>
            Curves show our hp-scaling law predictions, with shaded regions representing parameter uncertainty bounds from the sampling-based fitting strategy.
            Both plots use double logarithmic scaling (1912 training samples).
          </figcaption>
        </figure>
      </div>
    </div>
  </div>
</section>



<!-- 工具 -->
<section class="section">
  
  <div class="container is-max-desktop">
    <h2 class="title is-3 elegant-title" id="steplawtool">Step Law Tools</h2>
    <div class="tool-container">
      <div class="tool-loading" id="toolLoader">
        <div class="lds-ring">
          <div></div><div></div><div></div><div></div>
        </div>
      </div>
      <iframe src="tool.html" 
              class="tool-iframe"
              loading="lazy"
              title="Hyperparameter Optimization Tool"
              onload="document.getElementById('toolLoader').style.display='none'"></iframe>
    </div>
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 elegant-title">BibTeX</h2>
    <pre><code>@misc{li2025predictablescalei,
  title    = {Predictable Scale: Part I -- Optimal Hyperparameter Scaling Law in Large Language Model Pretraining}, 
  author   = {Houyi Li and Wenzheng Zheng and Jingcheng Hu and Qiufeng Wang and Hanshan Zhang and Zili Wang and Shijie Xuyang and Yuantao Fan and Shuigeng Zhou and Xiangyu Zhang and Daxin Jiang},
  year     = {2025},
  eprint   = {2503.04715},
  archivePrefix = {arXiv},
  primaryClass  = {cs.LG},
  url      = {https://arxiv.org/abs/2503.04715}, 
}
</code></pre>
  </div>

  <div class="institutional-logos" style="margin-top: 2rem;">
    <div style="display: flex; flex-wrap: wrap; gap: 0px; width: 100%; justify-content: center;">
        <div style="margin: 10px 20px; display: flex; justify-content: center;">
            <a href="https://platform.stepfun.com" target="_blank" style="display: flex; justify-content: center;">
                <img src="./static/images/logo1.png" alt="StepFun Logo" style="height: 90px;">
            </a>
        </div>
        <div style="margin: 10px 20px; display: flex; justify-content: center;">
            <a href="https://www.fudan.edu.cn" target="_blank" style="display: flex; justify-content: center;">
                <img src="./static/images/logo2.png" alt="Fudan Logo" style="height: 90px;">
            </a>
        </div>
        <div style="margin: 10px 20px; display: flex; justify-content: center;">
            <a href="https://www.tsinghua.edu.cn" target="_blank" style="display: flex; justify-content: center;">
                <img src="./static/images/logo3.png" alt="Tsinghua Logo" style="height: 90px;">
            </a>
        </div>
        <div style="margin: 10px 20px; display: flex; justify-content: center;">
            <a href="https://www.megvii.com" target="_blank" style="display: flex; justify-content: center;">
                <img src="./static/images/logo4.png" alt="Megvii Logo" style="height: 90px;">
            </a>
        </div>
    </div>
  </div>
</section>



<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link" href="">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on the <a href="https://nerfies.github.io">Nerfies</a> project page. 
            If you want to reuse their <a href="https://github.com/nerfies/nerfies.github.io">source code</a>, 
            please credit them appropriately.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false }
      ],
      throwOnError: false
    });
  });
</script>

</body>
</html>
